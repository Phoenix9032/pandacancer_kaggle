{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as tdata\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import PIL.Image as Image\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import pytorch_lightning as pl\n",
    "from contribs.ranger import Ranger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TileDataset(tdata.Dataset):\n",
    "    \n",
    "    def __init__(self, img_path, dataframe, transform=None, normalize_stats=None):\n",
    "        \n",
    "        self.img_path = Path(img_path)\n",
    "        self.df = df_train\n",
    "        self.img_list = self.df['image_id'].values\n",
    "        self.transform = transform\n",
    "        if normalize_stats is not None:\n",
    "            self.normalize_stats = {}\n",
    "            for k, v in normalize_stats.items():\n",
    "                self.normalize_stats[k] = transforms.Normalize(v[0], v[1])\n",
    "        else:\n",
    "            self.normalize_stats = None\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_list[idx]\n",
    "        \n",
    "        tiles = self.img_path.glob('**/' + img_id + '*.png')\n",
    "        metadata = self.df.iloc[idx]\n",
    "        image_tiles = []\n",
    "        for tile in tiles:\n",
    "            image = Image.open(tile)\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                image = self.transform(image)\n",
    "                \n",
    "            if self.normalize_stats is not None:\n",
    "                provider = metadata['data_provider']\n",
    "                image = self.normalize_stats[provider](image)\n",
    "                image_tiles.append(image)\n",
    "                \n",
    "        image_tiles = torch.stack(image_tiles, dim=0)\n",
    "        \n",
    "        return {'image':image_tiles, 'provider':metadata['data_provider'], \n",
    "                'isup':metadata['isup_grade'], 'gleason':metadata['gleason_score']}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base = models.resnet50(pretrained=True)\n",
    "        self.base.fc = nn.Linear(2048, 6)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = x.view(-1, 3, 128, 128)\n",
    "        h = self.base(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, train_idx, val_idx):\n",
    "        super().__init__()\n",
    "        self.train_idx = train_idx\n",
    "        self.val_idx = val_idx\n",
    "        self.model = Model()\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        return self.model(batch['image'])\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        with open('./stats.pkl', 'rb') as file:\n",
    "            provider_stats = pickle.load(file)\n",
    "        transform_train = transforms.Compose([transforms.ToTensor()])\n",
    "        transform_test = transforms.Compose([transforms.ToTensor()])\n",
    "        self.trainset = TileDataset(TRAIN_PATH, df_train.iloc[self.train_idx], transform=transform_train, normalize_stats=provider_stats)\n",
    "        self.valset = TileDataset(TRAIN_PATH, df_train.iloc[self.val_idx], transform=transform_test, normalize_stats=provider_stats)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        train_dl = tdata.DataLoader(self.trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        return train_dl\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        val_dl = tdata.DataLoader(self.valset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        return [val_dl]\n",
    "    \n",
    "    def cross_entropy_loss(self, logits, gt):\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        return loss_fn(logits, gt)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Ranger(self.model.parameters())\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        logits = self(batch)\n",
    "        loss = self.cross_entropy_loss(logits, batch['isup']).unsqueeze(0)\n",
    "        return {'loss': loss, 'log': {'train_loss': loss}}\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        logits = self(batch)\n",
    "        loss = self.cross_entropy_loss(logits, batch['isup']).unsqueeze(0)\n",
    "        preds = logits.argmax(1)\n",
    "        return {'val_loss': loss, 'preds': preds, 'gt': batch['isup']}\n",
    "    \n",
    "    def validation_end(self, outputs):\n",
    "        avg_loss = torch.cat([out['val_loss'] for out in outputs], dim=0).mean()\n",
    "        preds = torch.cat([out['preds'] for out in outputs], dim=0)\n",
    "        gt = torch.cat([out['gt'] for out in outputs], dim=0)\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        gt = gt.detach().cpu().numpy()\n",
    "        kappa = cohen_kappa_score(preds, gt)\n",
    "        tensorboard_logs = {'val_loss': avg_loss, 'kappa': kappa}\n",
    "        \n",
    "        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'G:/Datasets/panda/train_tiles/imgs/'\n",
    "CSV_PATH = 'G:/Datasets/panda/train.csv'\n",
    "SEED = 34\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(CSV_PATH)\n",
    "df_train = df_train[~(df_train['image_id'].isin(['8d90013d52788c1e2f5f47ad80e65d48']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n",
    "splits = kfold.split(df_train, df_train['isup_grade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx = next(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranger optimizer loaded. \n",
      "Gradient Centralization usage = True\n",
      "GC applied to both conv and fc layers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6413cbd260d6425693967201d60f5fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation sanity check', layout=Layout(flex='2'), max=5.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50d3069433f4e7ab62110cdc1cebe4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aea5dcf2b4943148780dff62d9ee119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1327.0, style=P…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d843b75a18cb42e0ad015ea517bb70be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1327.0, style=P…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce409fed41540e3b5d8c6def33accf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=1327.0, style=P…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightModel(train_idx, val_idx)\n",
    "trainer = pl.Trainer(gpus=[0])\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
